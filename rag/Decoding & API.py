import os
import json
import re
import faiss
import numpy as np
import torch
from functools import lru_cache
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from sentence_transformers import SentenceTransformer
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# ================== CONFIG ==================
BASE = os.path.dirname(__file__)
INDEX_FILE = os.path.join(BASE, "hailstate_index.faiss")
METADATA_FILE = os.path.join(BASE, "hailstate_metadata.json")

EMBED_MODEL_NAME = "jinaai/jina-embeddings-v3"
MODEL_NAME = "ALLaM-AI/ALLaM-7B-Instruct-preview"
TOP_K = 5

# ================== EMBEDDING MODEL ==================
embed_model = SentenceTransformer(
    EMBED_MODEL_NAME,
    trust_remote_code=True,
    device="cuda" if torch.cuda.is_available() else "cpu"
)
EMBED_DIM = embed_model.get_sentence_embedding_dimension()

# ================== LOAD FAISS & METADATA ==================
index = faiss.read_index(INDEX_FILE)

with open(METADATA_FILE, "r", encoding="utf-8") as f:
    metadata = json.load(f)

# ================== LLM ==================
@lru_cache(maxsize=1)
def load_llm():
    tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)
    mdl = AutoModelForCausalLM.from_pretrained(
        MODEL_NAME,
        torch_dtype=(torch.bfloat16 if torch.cuda.is_available() else torch.float32),
        device_map=("auto" if torch.cuda.is_available() else None),
    )
    mdl.eval()
    return tok, mdl

_tokenizer, _model = load_llm()
generator = pipeline("text-generation", model=_model, tokenizer=_tokenizer)

# ================== HELPERS ==================
def clean_llm_output(gen: str) -> str:
    """Extract the answer between <answer> tags if present"""
    if not gen:
        return ""
    m = re.search(r"<answer>(.*?)</answer>", gen, flags=re.S)
    if m:
        return m.group(1).strip()
    m2 = re.search(r"<answer>(.*)", gen, flags=re.S)
    if m2:
        return m2.group(1).strip()
    return gen.strip()

def format_record_for_context(rec: dict) -> str:
    """Convert metadata record into a clean Arabic context string for the prompt"""
    global metadata

    typ = rec.get("_type", "")
    parts = [f"Ø§Ù„Ù†ÙˆØ¹: {typ}"]

    def add_coords(parts, rec):
        lat = rec.get('Latitude', '?')
        lon = rec.get('Longitude', '?')
        parts.append(f"Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª: {lat}, {lon}")

    if typ == "governorate":
        parts.append(f"Ø§Ù„Ø§Ø³Ù…: {rec.get('governoratename')}")
        parts.append(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙƒØ§Ù†: {rec.get('Population', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')} (Ø°ÙƒÙˆØ± {rec.get('MaleCount','?')}, Ø¥Ù†Ø§Ø« {rec.get('FemaleCount','?')})")

        province_id = rec.get("ProvinceId") or rec.get("ID")
        if province_id:
            province_id_str = str(province_id)
            count_govs_in_province = sum(
                1 for g in metadata
                if g.get("_type") == "governorate" and str(g.get("ProvinceId")) == province_id_str
            )
            if count_govs_in_province > 0:
                parts.append(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø§Øª ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©: {count_govs_in_province}")

        parts.append(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†: {rec.get('GovernmentEmployeesCount', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}")
        parts.append(f"Ø¹Ø¯Ø¯ Ù…Ù„Ø§Ùƒ Ø§Ù„Ù…Ù†Ø§Ø²Ù„: {rec.get('HouseholdCount', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}")
        add_coords(parts, rec)

    elif typ == "hospital":
        parts.append(f"Ø§Ù„Ø§Ø³Ù…: {rec.get('hospitalname')}")
        parts.append(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡: {rec.get('TotalDoctors', '?')}")
        parts.append(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù…Ø±Ø¶Ø§Øª: {rec.get('TotalNurses', '?')}")
        parts.append(f"Ø§Ù„Ø£Ø³Ø±Ø© Ø§Ù„ÙƒÙ„ÙŠØ©: {rec.get('TotalBedsCount', '?')}")
        parts.append(f"Ø§Ù„Ø£Ø³Ø±Ø© Ø§Ù„Ø´Ø§ØºØ±Ø©: {rec.get('VacantBedsCount', '?')}")
        parts.append(f"Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¥Ø³Ø¹Ø§Ù: {rec.get('AmbulanceCount', '?')}")
        add_coords(parts, rec)

    elif typ == "school":
        parts.append(f"Ø§Ù„Ø§Ø³Ù…: {rec.get('schoolname')}")
        parts.append(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø§Ø¨: {rec.get('StudentsMale','?')} Ø°ÙƒÙˆØ±ØŒ {rec.get('StudentsFemale','?')} Ø¥Ù†Ø§Ø«")
        parts.append(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†: {rec.get('TeacherCount','?')}")

        province_id = rec.get("ProvinceId")
        if province_id:
            province_id_str = str(province_id)
            count_schools_in_province = sum(
                1 for s in metadata
                if s.get("_type") == "school" and str(s.get("ProvinceId")) == province_id_str
            )
            if count_schools_in_province > 0:
                parts.append(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø©: {count_schools_in_province}")

        add_coords(parts, rec)

    return " - ".join([str(p) for p in parts if p])

#=================Allocation / distance==================
import re
import math

def extract_lat_lon_and_patients(text):
    """Extract coordinates and number of patients using regex."""
    coord_match = re.search(r"\(?\s*([0-9]+\.[0-9]+)\s*,\s*([0-9]+\.[0-9]+)\s*\)?", text)
    patient_match = re.search(r"(\d+)\s*(?:Ù…Ø±ÙŠØ¶|Ù…Ø±Ø¶Ù‰|Ø§ØµØ§Ø¨Ø§Øª|Ø­Ø§Ù„Ø©)", text)

    lat = float(coord_match.group(1)) if coord_match else None
    lon = float(coord_match.group(2)) if coord_match else None
    num_patients = int(patient_match.group(1)) if patient_match else None

    return lat, lon, num_patients


def haversine(lat1, lon1, lat2, lon2):
    """Calculate distance between two points in KM."""
    R = 6371
    phi1, phi2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dlambda = math.radians(lon2 - lon1)
    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2
    return 2 * R * math.atan2(math.sqrt(a), math.sqrt(1 - a))


def search_nearest_hospital_in_metadata(lat, lon):
    """Scan metadata directly for hospitals and find the nearest one."""
    hospitals = [rec for rec in metadata if rec.get("_type") == "hospital"]
    nearest = None
    min_distance = float('inf')

    for h in hospitals:
        h_lat = h.get("Latitude")
        h_lon = h.get("Longitude")
        if not h_lat or not h_lon:
            continue

        dist = haversine(lat, lon, float(h_lat), float(h_lon))
        if dist < min_distance:
            min_distance = dist
            nearest = (h, dist)

    return nearest

# ================== UNIFIED PROMPT ==================
def build_unified_prompt(user_query: str, retrieved_contexts: list[str]) -> str:
    """
    Creates a single structured prompt to handle normal, geographic, and conditional queries.
    """
    prompt = f"""
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙˆÙ…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠØ© ÙˆØ§Ù„Ø·Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©.
ØªØ¬ÙŠØ¨ ÙÙ‚Ø· Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰.
Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªØ­Ù„ÙŠÙ„ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ ÙÙ‡Ù… Ù‚ØµØ¯Ù‡ (Ø¹Ø§Ø¯ÙŠ Ø£Ùˆ Ø¬ØºØ±Ø§ÙÙŠ Ø£Ùˆ Ø´Ø±Ø·ÙŠ)ØŒ Ø«Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø¯Ù‚Ø© Ø§Ø¹ØªÙ…Ø§Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ù…Ø© ÙÙ‚Ø·.

ğŸ‘‡ Ø§ØªØ¨Ø¹ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø¯Ù‚Ø©:
1ï¸âƒ£ - Ø§Ù‚Ø±Ø£ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¬ÙŠØ¯Ù‹Ø§ØŒ ÙˆØ­Ø¯Ø¯ Ù†ÙˆØ¹Ù‡:
   - Ø³Ø¤Ø§Ù„ Ø¹Ø§Ø¯ÙŠ: Ù…Ø«Ù„ "ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙƒØ§Ù† ÙÙŠ Ù…Ø­Ø§ÙØ¸Ø© Ø§Ù„Ø´Ù†Ø§Ù†ØŸ"
   - Ø³Ø¤Ø§Ù„ Ø¬ØºØ±Ø§ÙÙŠ: Ù…Ø«Ù„ "Ù…Ø§ Ù‡ÙŠ Ø£Ù‚Ø±Ø¨ Ù…Ø³ØªØ´ÙÙ‰ Ù„Ù„Ù…ÙˆÙ‚Ø¹ (41.7 , 27.5)ØŸ"
   - Ø³Ø¤Ø§Ù„ Ø´Ø±Ø·ÙŠ: Ù…Ø«Ù„ "Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ 10 Ù…Ø±Ø¶Ù‰ ÙÙŠ Ø§Ù„Ù…ÙˆÙ‚Ø¹ (41.7 , 27.5) Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ø£Ù†Ø³Ø¨ØŸ"

2ï¸âƒ£ - Ø§Ø³ØªØ®Ø±Ø¬ Ø£ÙŠ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø£Ùˆ Ø£Ø¹Ø¯Ø§Ø¯ Ù…Ø±Ø¶Ù‰ Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ù† ÙˆØ¬Ø¯Øª.

3ï¸âƒ£ - Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙ‚Ø· (ÙˆÙ„Ø§ ØªØ¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø®Ø§Ø±Ø¬Ù‡Ø§) Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©:
{chr(10).join(retrieved_contexts)}

4ï¸âƒ£ - Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø£ÙŠ Ø¥Ø¬Ø§Ø¨Ø© ÙˆØ§Ø¶Ø­Ø© Ø£Ùˆ Ù…Ù†Ø§Ø³Ø¨Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø¨Ù€:
ØºÙŠØ± Ù…ØªÙˆÙØ±


ğŸ“ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
```{user_query}```

<answer>
""".strip()
    return prompt

# ================== RAG CORE ==================
def rag_query(user_query: str):
    # 1ï¸âƒ£ Extract coordinates from user question
    lat, lon, num_patients = extract_lat_lon_and_patients(user_query)

    # 2ï¸âƒ£ If geo â†’ direct metadata search
    if lat and lon:
        nearest = search_nearest_hospital_in_metadata(lat, lon)
        if not nearest:
            return "âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø³ØªØ´ÙÙ‰ Ù‚Ø±ÙŠØ¨Ø©."

        hospital, distance_km = nearest
        context = [
            f"Ø§Ù„Ø§Ø³Ù…: {hospital['hospitalname']}",
            f"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø±Ø© Ø§Ù„ÙƒÙ„ÙŠØ©: {hospital.get('TotalBedsCount', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}",
            f"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø±Ø© Ø§Ù„Ø´Ø§ØºØ±Ø©: {hospital.get('VacantBedsCount', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}",
            f"Ø§Ù„Ù…ÙˆÙ‚Ø¹: ({hospital['Latitude']}, {hospital['Longitude']})",
            f"Ø§Ù„Ù…Ø³Ø§ÙØ© Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {round(distance_km, 2)} ÙƒÙ…"
        ]

        prompt = build_unified_prompt(user_query, context)
        gen = generator(prompt, max_new_tokens=200, do_sample=False)[0]["generated_text"]
        return clean_llm_output(gen)

    # 3ï¸âƒ£ Else â†’ normal FAISS retrieval
    q_emb = embed_model.encode([user_query], convert_to_numpy=True)
    q_emb = q_emb / np.maximum(np.linalg.norm(q_emb, axis=1, keepdims=True), 1e-9)
    _, I = index.search(q_emb.astype("float32"), TOP_K)
    contexts = [format_record_for_context(metadata[int(i)]) for i in I[0] if i != -1]

    if not contexts:
        return "ØºÙŠØ± Ù…ØªÙˆÙØ±."

    prompt = build_unified_prompt(user_query, contexts)
    gen = generator(prompt, max_new_tokens=200, do_sample=False)[0]["generated_text"]
    return clean_llm_output(gen)
BASE = os.path.abspath(os.path.dirname(__file__))
STATIC_DIR = os.path.join(BASE, "static")

# ================== FASTAPI SERVER ==================
app = FastAPI(
    title="RAG Chat API",
    description="Arabic RAG Model for Web & Java/C++ Clients",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, RedirectResponse

app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

@app.get("/")
def root():
    return RedirectResponse("/chat")

@app.get("/chat")
def get_chat_page():
    return FileResponse(os.path.join(STATIC_DIR, "index.html"))

class ChatRequest(BaseModel):
    query: str

class ChatResponse(BaseModel):
    answer: str

@app.post("/api/chat", response_model=ChatResponse)
def chat(req: ChatRequest):
    answer = rag_query(req.query)
    return {"answer": answer or "ØºÙŠØ± Ù…ØªÙˆÙØ±."}

# ================== MAIN ==================
if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
